← [Back to Home](../index.md)

<h1 align="center">Artifact Reference</h1>

Every run generates a complete artifact suite for total traceability. Both training-only and optimization workflows share the same `RunPath` orchestrator, producing BLAKE2b-hashed timestamped directories.

<h2>Directory Structure</h2>

<h3>Standard Training Run</h3>

```
outputs/20260123_bloodmnist_minicnn_b4a8f1/
├── figures/
│   ├── confusion_matrix.png           # Per-class prediction matrix
│   ├── training_curves.png            # Loss/AUC over epochs
│   ├── training_curves.npz            # Raw metrics data for custom plots
│   └── sample_grid.png                # Augmentation preview (12 samples)
├── reports/
│   ├── training_summary.xlsx          # Complete metrics spreadsheet
│   ├── config_snapshot.yaml           # Frozen config at run start
│   └── requirements.txt              # Pinned pip freeze at run start
├── checkpoints/
│   └── best_mini_cnn.pth              # Best model weights (by val AUC)
├── exports/
│   └── model.onnx                     # Production-ready ONNX export
└── logs/
    └── orchestrator_YYYYMMDD_HHMMSS.log
```

<h3>Optimization Run</h3>

Optimization runs include all standard artifacts plus additional analysis files:

```
outputs/20260123_organcmnist_efficientnetb0_a3f7c2/
├── figures/
│   ├── confusion_matrix.png           # Final model predictions
│   ├── training_curves.png            # Best trial training curves
│   ├── training_curves.npz            # Raw metrics data
│   ├── sample_grid.png                # Augmentation preview
│   ├── param_importances.html         # Interactive importance plot
│   ├── optimization_history.html      # Trial progression over time
│   ├── slice.html                     # 1D parameter effect analysis
│   └── parallel_coordinate.html       # Multi-dimensional parameter view
├── reports/
│   ├── training_summary.xlsx          # Best trial metrics
│   ├── config_snapshot.yaml           # Initial config
│   ├── requirements.txt              # Pinned pip freeze at run start
│   ├── best_config.yaml               # Optimized hyperparameters
│   ├── study_summary.json             # All trials metadata
│   └── top_10_trials.xlsx             # Best configurations ranked
├── checkpoints/
│   └── best_efficientnet_b0.pth       # Best model weights
├── exports/
│   └── model.onnx                     # Production export
├── database/
│   └── study.db                       # SQLite storage for resumption
└── logs/
    └── orchestrator_YYYYMMDD_HHMMSS.log
```

<h2>Artifact Details</h2>

<h3>Figures</h3>

| File | Description | Generated By |
|------|-------------|--------------|
| `confusion_matrix.png` | Per-class prediction heatmap showing true vs predicted labels | Training, Optimization |
| `training_curves.png` | Loss and AUC metrics plotted over epochs | Training, Optimization |
| `training_curves.npz` | NumPy archive with raw curve data for custom visualization | Training, Optimization |
| `sample_grid.png` | 12-sample grid showing augmentation effects | Training, Optimization |
| `param_importances.html` | Interactive Plotly chart showing hyperparameter importance | Optimization only |
| `optimization_history.html` | Trial progression showing objective value over time | Optimization only |
| `slice.html` | 1D parameter slice plots showing individual parameter effects | Optimization only |
| `parallel_coordinate.html` | Multi-dimensional view of parameter relationships | Optimization only |

<h3>Reports</h3>

| File | Description | Generated By |
|------|-------------|--------------|
| `config_snapshot.yaml` | Frozen configuration at run start (immutable record) | Training, Optimization |
| `requirements.txt` | Pinned `pip freeze` output capturing exact dependency versions | Training, Optimization |
| `training_summary.xlsx` | Excel spreadsheet with metrics, predictions, and class-wise breakdown | Training, Optimization |
| `best_config.yaml` | Optimized hyperparameters ready for production training | Optimization only |
| `study_summary.json` | Complete study metadata including all trial results | Optimization only |
| `top_10_trials.xlsx` | Top 10 configurations ranked by objective value | Optimization only |

<h3>Models & Exports</h3>

| File | Description | Generated By |
|------|-------------|--------------|
| `best_<arch>.pth` | PyTorch checkpoint with best model weights (selected by validation AUC) | Training, Optimization |
| `model.onnx` | ONNX export for production deployment (opset 18, dynamic batch) | Training, Optimization |

<h3>Database</h3>

| File | Description | Generated By |
|------|-------------|--------------|
| `study.db` | SQLite database storing Optuna study state for resumption | Optimization only |

<h2>Sample Artifacts</h2>

Explore real experiment outputs in the [artifacts directory](../artifacts/):

- **Excel Reports**: Training metrics, predictions, class-wise analysis
- **YAML Configs**: Frozen configurations and optimized hyperparameters
- **HTML Visualizations**: Interactive Plotly charts for optimization analysis

---

← [Back to Home](../index.md) | [Optimization Guide](OPTIMIZATION.md) | [Export Guide](EXPORT.md)
